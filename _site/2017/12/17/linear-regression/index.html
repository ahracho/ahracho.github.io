<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>[Machine Learning] 선형회귀 (Linear Regression)</title>
    <meta name="description" content="선형회귀모델이번 포스트부터는 드디어 실제로 기계학습에서 사용되는 모델들과 적용 방법들을 다룰 것이다. 어느 입문서에서든 가장 먼저 설명하는 모델이 선형회귀모델인데, 여러 모델 중에서 가장 이해하기 쉽고, 간단한 모델이기 때문이다.통계학개론을 배운 사람이라면 기본적인 회귀분석 모델에...">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/2017/12/17/linear-regression/">
    <link rel="alternate" type="application/rss+xml" title="AHRA's Tech Blog" href="http://localhost:4000/feed.xml ">





</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/" class="brand">AHRA's Tech Blog</a>
        <small>Learn and Share</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>Tags
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About Me
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" post>
    <div class="left">
        <h1>[Machine Learning] 선형회귀 (Linear Regression)</h1>
        <div class="label">

            <div class="label-card">
                <i class="fa fa-calendar"></i>2017-12-17
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
                
            </div>

            <div class="label-card">
            


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Machine-Learning" title="Category: Machine-Learning" rel="category">Machine-Learning</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


            </div>

            <div class="label-card">
            
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <!--a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a-->
        <a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a>&nbsp;
    
        <!--a href="/tag/#Linear-Regression" title="Tag: Linear-Regression" rel="tag">Linear-Regression</a-->
        <a href="/tag/#Linear-Regression" title="Tag: Linear-Regression" rel="tag">Linear-Regression</a>&nbsp;
    
        <!--a href="/tag/#%EC%A7%80%EB%8F%84%ED%95%99%EC%8A%B5" title="Tag: 지도학습" rel="tag">지도학습</a-->
        <a href="/tag/#지도학습" title="Tag: 지도학습" rel="tag">지도학습</a>&nbsp;
    
        <!--a href="/tag/#Beginner" title="Tag: Beginner" rel="tag">Beginner</a-->
        <a href="/tag/#Beginner" title="Tag: Beginner" rel="tag">Beginner</a>
    
  

</span>

            </div>

        </div>
        <hr>
        <article itemscope itemtype="http://schema.org/BlogPosting">
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h2 id="선형회귀모델">선형회귀모델</h2>
<p>이번 포스트부터는 드디어 실제로 기계학습에서 사용되는 모델들과 적용 방법들을 다룰 것이다. 어느 입문서에서든 가장 먼저 설명하는 모델이 선형회귀모델인데, 여러 모델 중에서 가장 이해하기 쉽고, 간단한 모델이기 때문이다.</p>

<p>통계학개론을 배운 사람이라면 기본적인 회귀분석 모델에 대한 지식은 있을테지만, 간단히 설명하자면 종속변수 X와 독립변수 Y의 n차 관계식을 찾는 모델이라고 생각하면 된다. 함수식을 찾는다고 생각하면 될 것이다. 회귀분석 모델에서 가장 많이 언급되는 것이 바로 이번 포스트에서 설명할 선형회귀 모델인데, 이름에서도 나타나듯이 X와 Y의 관계를 선형으로 나타내는 모델을 의미한다. 선형이라는 것은 간단히 1차식으로 표현한다고 이해하면 된다.</p>

<p>아래와 같은 데이터가 있다고 가정해보자.<br />
<img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/linear_regression_sample.png" alt="선형회귀" /><br />
가로축 X와 세로축 Y가 정확히 어떻게 관계인지는 몰라도 X와 Y를 어느정도 직선으로 표현할 수 있다는 것은 눈치챌 수 있다. 선형회귀모델은 X와 Y의 관계를 가장 잘 나타내는 직선을 찾아내는 과정이다.</p>

<p><img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/1_supervised_linear_regression_definition.JPG" alt="선형회귀" /></p>

<p>선형회귀 모델은 크게 두가지로 나뉘는데, 설명 변수 X가 하나인 경우는 단순선형회귀, 여러 개인 경우는 다중선형회귀라고 한다. 선형회귀 모델은 X와 Y의 관계를 1차식으로 나타내는 것이기 때문에 두 경우 모두 간단히 아래와 같은 식으로 표현할 수 있다.</p>

<p>\({y=Wx+b}\)</p>

<p>다만, 단순선형회귀의 경우는 x 위치에 하나의 실수가 들어가고, 다중선형회귀는 여러 실수를 담은 벡터가 들어간다(자세한 내용은 마지막 챕터에서 다루는 것으로 한다). 식에서 W는 가중치(Weight)로 결과값 Y에 설명변수 X가 얼마나 영향을 주는지 나타낸다. b는 편향(또는 오차항)을 나타내는데, X만으로 설명할 수 없는 모든 오차값들을 표현한다.</p>

<p>기계학습을 통해서 우리는 X와 Y의 관계를 가장 잘 표현하는 관계식을 찾는다는 것은, 결국 가장 적절한 W와 b값을 찾는다는 것을 의미한다.</p>

<h2 id="단순선형회귀">단순선형회귀</h2>
<p><img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/2_supervised_linear_regression_one_variable.JPG" alt="단순선형회귀" /></p>

<p>단순선형회귀는 결과값 Y에 영향을 미치는 변수가 하나라는 가정이다. 위에서 본 그래프와 같이 하나의 X와 대응되는 Y값이 주어질 때 둘의 관계를 찾는 것이다. 따라서 W와 b 값은 모두 하나의 실수로 구성된다. 학습의 결과는 \({y’=0.5x+3}\) 과 같이 최종 W와 b 값으로 대치된 하나의 식으로 나타날 것이다.</p>

<p>그렇다면 가장 적절한 W와 b 값은 어떤 과정을 찾아내는 것일까? 지난 포스트까지 설명했던 학습과정을 그대로 적용하면 된다.</p>
<ol>
  <li>모델(또는 가설)을 세워서 적용하고,</li>
  <li>세운 가설을 평가하고,</li>
  <li>평가를 바탕으로 가설을 업데이트한다.</li>
</ol>

<p>여기서 ‘모델’이라고 한 것은 특정한 W와 b값을 적용한 관계식인데, 위의 과정을 우리가 알고 있는 과정에 대입하면 아래와 같다.</p>
<ol>
  <li>\({y’=0.5x+3}\)라는 모델을 가지고 예측값 y’를 계산한다.</li>
  <li>MSE를 사용하여 실제값 y와 예측값 y’의 오차를 계산한다.</li>
  <li>오차에 따라 경사하강법으로 W와 b 값을 업데이트한다.</li>
</ol>

<p>실제 데이터에 적용해보자. 먼저 예제에 사용할 (x, y) 데이터쌍 200개를 생성한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">()</span> <span class="p">:</span>
    <span class="n">data_size</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_size</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
    <span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
</code></pre></div></div>

<p>첫번째 Iteration을 위해 W와 b의 초기값을 설정한다. 보통 W값은 랜덤으로, b값은 0으로 시작한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">model</span><span class="p">[</span><span class="s">'W'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
<span class="n">model</span><span class="p">[</span><span class="s">'b'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="c"># 일반 파이썬 리스트에서 numpy array로 변환</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>
</code></pre></div></div>

<p>위에서 설명한 세가지 과정을 코드로 표현해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. 현재의 모델로 예측값 y'를 계산</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">x_data</span>
    <span class="k">return</span> <span class="n">x_data</span> <span class="o">*</span> <span class="n">model</span><span class="p">[</span><span class="s">'W'</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="p">[</span><span class="s">'b'</span><span class="p">]</span>


<span class="c"># 2. 오차 계산 (MSE)</span>
<span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"MSE model : "</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">global</span> <span class="n">x_data</span>
    <span class="k">global</span> <span class="n">y_data</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c"># 현재의 가설을 바탕으로 x 데이터에 대한 예측값 y를 리턴하는 함수</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># 훈련 데이터의 개수</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y_predict</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"loss : "</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mse</span>


<span class="c"># 편미분 계산</span>
<span class="k">def</span> <span class="nf">derivative</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">temp</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
        <span class="n">plus</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
        
        <span class="c"># 원래는 (+h ~ -h) 한 값의 기울기를 구하는 게 더 정확하다</span>
        <span class="n">grads</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">plus</span> <span class="o">-</span> <span class="n">function</span><span class="p">(</span><span class="n">model</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">grads</span>


<span class="c"># 3. 경사하강법으로 변수 업데이트</span>
<span class="k">def</span> <span class="nf">gradient_descent_with_derivative</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">model</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">derivative</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    
    <span class="c"># 편미분 구한 값을 learning rate만큼 반영하여 업데이트</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
    

<span class="c"># 실제로 테스트해보자</span>
<span class="c"># 100번을 실험하면서 W와 b 값이 어떻게 변화하는지 살펴본다</span>
<span class="n">iteration</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
    <span class="n">gradient_descent_with_derivative</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"model : "</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<p>실험을 하면서 주의깊게 봐야하는 값은 사실 Loss이다. 학습의 목표가 Loss 값을 최소화하는 것임을 기억하면, Iteration이 계속되면서 Loss 값이 점점 커지는 상황이 발생했을 때, learning rate을 조절해서 Loss가 발산하지 않도록 수정해야 한다. Learning Rate은 W와 b 값을 업데이트 할 때 한번에 움직이는 보폭을 얼마나 크게 할 것인지 결정하는 변수이다. Loss 값이 발산한다는 것은 한번에 너무 많이 움직인다는 것을 의미하기 때문에 이럴 때는 Learning Rate을 더 작게 해서 보폭을 작게 만들어야 한다.</p>

<h2 id="tensorflow-이용해서-구현하기">Tensorflow 이용해서 구현하기</h2>
<p>사실 파이썬만으로도 기계학습 알고리즘을 구현할 수는 있지만 위에서 보듯이 코드가 복잡해지고 작성자가 신경써야할 부분도 많아진다. 그래서 보통 기계학습 알고리즘을 적용할 때 본인이 직접 모든 코드를 구현하기 보다 미리 만들어져 있는 소스를 활용하는데 가장 많이 사용되는 것이 구글에서 제공하는 Tensorflow이다. Tensorflow를 활용하면 Gradient Descent나 Loss 계산 이런 것들을 미리 만들어져있는 함수에 맡기고 우리는 틀만 짜주면 된다.</p>

<p>Tensorflow를 활용하면 위의 복잡한 코드가 아래처럼 간단해진다. 물론 그 전에 Tensorflow 패키지를 모두 설치해야 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> 
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>

<span class="c"># Tensorflow를 사용할 때는 학습을 진행하기 전에</span>
<span class="c"># 먼저 어떠한 방식으로 학습시킬지 변수들을 먼저 설정해주어야 한다.</span>
<span class="c"># 설정해야 하는 변수에는 관계식 W와 b, Loss 함수, 최적화 방식 등이 있다.</span>

<span class="c"># tf.Variable() 함수는 학습시켜야 하는 변수를 만들어 준다.</span>
<span class="c"># 여기서 W와 b는 모두 실수 하나로 구성된다.</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="c"># x와 y의 관계식을 설정한다. </span>
<span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>
<span class="c"># loss는 실제값 y_data와 예측값 y의 MSE를 구하는 방식으로 설정</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">))</span>

<span class="c"># 최적화는 우리가 배운 Gradient Descent 방식을 사용한다.</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="c"># 학습은 loss로 설정한 MSE를 minimize(최소화) 하는 방식으로 사용한다.</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> 

<span class="c"># 여기까지는 학습 변수 설정이고</span>
<span class="c"># 실제 학습은 Session 안에서 이루어진다. </span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span> <span class="c"># 변수 W, b 초기화</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

<span class="c"># 그래프 출력</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>Loss 함수나 최적화 함수를 직접 작성할 때보다 코드가 훨씬 간결해졌다. Tensorflow를 활용하면 우리는 학습이 진행되면서 나오는 결과 분석에만 신경쓰면 되고, 나머지는 Tensorflow에 맡겨두면 된다. 앞으로 예제 코드는 Tensorflow를 사용하는 버전으로 작성하도록 하고, 우리는 원리를 이해하는 데 집중하도록 하자.</p>

        </article>
        <hr>

        
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <h2 id="similar_posts">Similar Posts</h2>
                        <ul>
                        
                        <li class="relatedPost">
                            <a href="/2018/06/21/kalman-filter-2/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (2)
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
            
            
                
                    
                        
                        <li class="relatedPost">
                            <a href="/2018/06/20/kalman-filter-1/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (1)
                            
                            </a>
                        </li>
                        
                        
                    
                
                    
                
                    
                
                    
                
            
                
                    
                
                    
                
                    
                
                    
                
            
        
        
            </ul>
        

        <div class="post-recent">
    <div class="pre">
        
        <p><strong>Prev</strong> <a href="/2017/12/09/gradient-descent/">[Machine Learning] 학습 프로세스 (3단계. 모델업데이트)</a></p>
        
    </div>
    <div class="nex">

        
        <p><strong>Next</strong> <a href="/2018/06/20/kalman-filter-1/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (1)</a></p>
        
    </div>
</div>


        <h2 id="comments">Comments</h2>
        
<div id="disqus_thread"></div>
<script>
    /**
     * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */

    var disqus_config = function() {
        this.page.url = 'http://localhost:4000/2017/12/17/linear-regression/'; // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'http://localhost:4000/2017/12/17/linear-regression/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };

    (function() { // DON'T EDIT BELOW THIS LINE
        var d = document,
            s = d.createElement('script');

        s.src = '//ahracho.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>




    </div>
    <button class="anchor"><i class="fa fa-anchor"></i></button>
    <div class="right">
        <div class="wrap">

            <!-- Content -->
            <div class="side content">
                <div>
                    Content
                </div>
                <ul id="content-side" class="content-ul">
                    
                    <li><a href="#similar_posts">Similar Posts</a></li>
                    
                    <li><a href="#comments">Comments</a></li>
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <!-- <div class="side">bbbb</div> -->
        </div>
    </div>
</div>
<script>
/**
 * target _blank
 */
(function() {
    var aTags = document.querySelectorAll('article a:not([id])')
    for (var i = 0; i < aTags.length; i++) {
        aTags[i].setAttribute('target', '_blank')
    }
}());
</script>
<script src="/js/pageContent.js " charset="utf-8"></script>


    <footer class="site-footer">


    <div class="wrapper">

        <p class="description">
            
        </p>
        <p class="contact">
            Contact me at: 
            <a href="https://github.com/ahracho" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:ahracho89@gmail.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>     
            <a href="https://www.facebook.com/ahra.cho3" title="Facebook"><i class="fa fa-facebook-official" aria-hidden="true"></i></a>    
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>
    </div>
</footer>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
    <!-- <script src=" /js/scroll.min.js " charset="utf-8"></script> -->
  </body>

</html>
