<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>AHRA&#39;s Tech Blog</title>
    <meta name="description" content="">

    <link rel="shortcut icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="icon" href="/favicon.ico?" type="image/x-icon">
    <link rel="stylesheet" href="https://cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://at.alicdn.com/t/font_8v3czwksspqlg14i.css">
    <link rel="stylesheet" href="/css/main.css ">
    <link rel="canonical" href="http://localhost:4000/page2/">
    <link rel="alternate" type="application/rss+xml" title="AHRA's Tech Blog" href="http://localhost:4000/feed.xml ">





</head>


  <body>

    <header id="top">
    <div class="wrapper">
        <a href="/" class="brand">AHRA's Tech Blog</a>
        <small>Learn and Share</small>
        <button id="headerMenu" class="menu"><i class="fa fa-bars"></i></button>
        <nav id="headerNav">
            <ul>
                <li>
                    
                    <a href="/">
                    
                        <i class="fa fa-home"></i>Home
                    </a>
                </li>

                
                    
                    <li>
                        
                        <a href="/archive/">
                        
                            <i class="fa fa-archive"></i>Archives
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/category/">
                        
                            <i class="fa fa-th-list"></i>Categories
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/tag/">
                        
                            <i class="fa fa-tags"></i>Tags
                        </a>
                    </li>
                    
                
                    
                    <li>
                        
                        <a href="/about/">
                        
                            <i class="fa fa-heart"></i>About Me
                        </a>
                    </li>
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
                    
                
            </ul>
        </nav>
    </div>
</header>


        <div class="page clearfix" index>
    <div class="left">
        <h1>Welcome to AHRA's Blog!</h1>
        <small>프로그래밍 필기노트</small>
        <hr>
        <ul>
            
              <li>
                <h2>
                  <a class="post-link" href="/2018/06/26/2_gaussian-elimination/">[선형대수] 2강 : 1차 연립방정식과 가우스소거법</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2018-06-26
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Linear-Algebra" title="Category: Linear-Algebra" rel="category">Linear-Algebra</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Math" title="Tag: Math" rel="tag">Math</a>&nbsp;
    
        <a href="/tag/#Linear-Algebra" title="Tag: Linear-Algebra" rel="tag">Linear-Algebra</a>&nbsp;
    
        <a href="/tag/#KMOOC" title="Tag: KMOOC" rel="tag">KMOOC</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <p>한양대 이상화 교수님의 오픈 강의로 공부한 내용을 정리한 것입니다. 강의 영상과 강의 노트는 다음 링크에서 다운받아 작성하였습니다.<br />
<a href="http://www.kocw.net/home/search/kemView.do?kemId=977757">http://www.kocw.net/home/search/kemView.do?kemId=977757</a></p>

<iframe src="//www.slideshare.net/slideshow/embed_code/key/LjLUIlWbCIbpsK" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe>
<div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/ahra-cho/02-108497093" title="선형대수 02. 가우스 소거법" target="_blank">선형대수 02. 가우스 소거법</a> </strong> from <strong><a href="https://www.slideshare.net/ahra-cho" target="_blank">AHRA CHO</a></strong> </div>

<hr />

<h2 id="gaussian-elimination">Gaussian Elimination</h2>
<p><strong>가우스 소거법</strong>은 행렬로 표현된 연립방정식에서 1행부터 차례로 적절한 값을 곱하고 서로 빼주면서 쉽게 해를 찾을 수 있는 형태로 변형하여 방정식의 해를 찾는 과정이다. 이 과정에서 계수행렬을 Upper Triangular Matrix로 변형하게 되는데, 행렬 U의 대각선 위치에 있는 값들을 Pivot이라고 한다.<br />
Non-Singular의 경우에는, Pivot이 모두 0이 아닌 값을 가지고, Pivot 중에 0인 값이 있으면 Singular Case로, 이 경우에는 해가 없거나, 무수히 많게 된다.</p>

<h2 id="matrix-notation">Matrix Notation</h2>
<p>Ax=b 형태로 작성된 연립방정식을 다시 풀어보면 상수와 벡터의 Linear Combination으로 표현할 수 있다. 지난 포스팅에서 설명했듯, 연립방정식을 벡터의 조합으로 이해했을 때, 행렬 A의 column vector들을 적절한 배수로 곱하고 더한 값(Linear Combination)이 우항의 벡터가 될 수 있는지를 구하는 것이 연립방정식을 푸는 과정이다.<br />
b를 행렬 A의 열벡터 조합으로 표현할 수 있다는 것은 b가 행렬 A가 표현하는 어떤 공간 안의 벡터라는 것이고, 연립방정식의 해가 (하나이든 무한개이든) 존재한다는 의미이다.</p>

                </div>
                <div class="read-all">
                    <a  href="/2018/06/26/2_gaussian-elimination/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2018/06/22/1_linearity/">[선형대수] 1강 : 선형성의 정의 및 1차 연립방정식의 의미</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2018-06-22
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Linear-Algebra" title="Category: Linear-Algebra" rel="category">Linear-Algebra</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Math" title="Tag: Math" rel="tag">Math</a>&nbsp;
    
        <a href="/tag/#Linear-Algebra" title="Tag: Linear-Algebra" rel="tag">Linear-Algebra</a>&nbsp;
    
        <a href="/tag/#KMOOC" title="Tag: KMOOC" rel="tag">KMOOC</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <p>한양대 이상화 교수님의 오픈 강의로 공부한 내용을 정리한 것입니다. 강의 영상과 강의 노트는 다음 링크에서 다운받아 작성하였습니다.<br />
<a href="http://www.kocw.net/home/search/kemView.do?kemId=977757">http://www.kocw.net/home/search/kemView.do?kemId=977757</a></p>

<iframe src="//www.slideshare.net/slideshow/embed_code/key/5lxPkvCZK1tQ3M" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> </iframe>
<div style="margin-bottom:5px"> <strong> <a href="//www.slideshare.net/ahra-cho/01-1-108458741" title="선형대수 01. 선형성의 정의와 1차 연립방정식의 의미" target="_blank">선형대수 01. 선형성의 정의와 1차 연립방정식의 의미</a> </strong> from <strong><a href="//www.slideshare.net/ahra-cho" target="_blank">AHRA CHO</a></strong> </div>

<hr />

<h2 id="선형성의-정의">선형성의 정의</h2>
<p>선형대수에서 다루는 주제들은 보통 행렬을 바탕으로 하는데, 행렬은 선형적인 관계를 나타내기 때문에 ‘선형적’이라는 것이 어떤 의미인지 이해하는 것이 중요하다.<br />
흔히 ‘선형함수’라고 하면 직선을 그리는 1차 방정식을 떠올리는 경우가 많다 (나 또한 그랬고). 하지만 Superposition과 Homogeneity 성질을 모두 만족할 때만 선형적이라고 말할 수 있다. 즉, 선형 함수는 Superposition과 Homogeneity 2가지 조건을 동시에 만족해야 한다.</p>

<h2 id="gaussian-elimination-가우스-소거법">Gaussian Elimination (가우스 소거법)</h2>
<p>중학교 때 배우던 1차 연립 방정식의 풀이법을 행렬로 바꾸어 계산하면 접근방법이 달라진다. 연립 방정식을 기하학적으로 접근하면, 두 직선의 교점을 찾는 문제이지만, 행렬로 접근하면 두 벡터에 각각 m, n배 하여 그 합이 특정한 값이 나오도록 하는 문제로 바뀐다. 기하학적인 방법이 직관적일 수는 있지만, 우리가 상상할 수 있는 공간이 최대 3차원으로 제한되어 있기 때문에 N차원의 방정식을 풀려고 하면 어려움을 겪는다. 하지만, 행렬로 접근하면 N차원의 행렬은 결국 N차원 벡터의 집합이기 때문에 훨씬 간단하게 풀 수 있다.</p>

<p>앞으로 행렬적인 접근 방법으로 N차원의 연립방정식을 푸는 방법, 역행렬을 찾는 방법 등에 대해서 다룰 것이다.</p>

                </div>
                <div class="read-all">
                    <a  href="/2018/06/22/1_linearity/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2018/06/21/kalman-filter-2/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (2)</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2018-06-21
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Udacity-SDCND" title="Category: Udacity-SDCND" rel="category">Udacity-SDCND</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a>&nbsp;
    
        <a href="/tag/#SelfDriving-Car" title="Tag: SelfDriving-Car" rel="tag">SelfDriving-Car</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    
<h2 id="extended-kalman-filter">Extended Kalman Filter</h2>

<p>칼만 필터는 센서 하나의 값만으로 사용하는 것이 아니라 여러 개의 센서 값을 동시에 사용할 수 있기 때문에 유용성이 크다. 자율주행차에서도 마찬가지인데, LADAR와 RIDAR 센서를 통해 얻어진 값을 조합하여 물체 인식과 움직임 예측에 사용한다. 센서를 여러 개 사용하더라도 앞선 포스팅에서 설명했던 기본적인 칼만 필터의 동작 방식은 동일하다. 센서값이 들어오면 예측을 하고, 예측 알고리즘을 업데이트를 하여 최종 예측값을 계산한다. 다만, 달라지는 것은 여러 개의 센서들이 번갈아가면서 값을 입력한다는 것이다.</p>

<p>LADAR와 RIDAR 센서는 특성도 다르고, 센서 계측값의 형태도 다르다. 물체의 (x,y) 좌표를 결과값으로 주는 LADAR 센서와 달리, RIDAR 센서는 다른 형태의 측정값을 출력한다 (거리, 각도, 속도 등). Prediction 단계에서는 LADAR / RIDAR 센서의 차이가 없지만, Measurement Update 단계에서는 센서에 따라 다른 식을 사용해야 한다. 특히, 예측값과 센서값을 비교하기 위한 식에서 x를 z(센서 출력값)와 같은 형태로 바꾸기 위한 행렬 H가 바뀌어야 한다. 여기서는 행렬 H 대신 함수 h(x)를 사용한다.</p>

<p><img src="http://localhost:4000/images/ml/udacity/ekf-note1.png" alt="Note1" title="h(x) function" /></p>

<p>Error 계산 뿐만 아니라, 행렬 S, K, P를 계산할 때에도 행렬 H가 사용되기 때문에, 이들도 변화가 필요하다. 이때 위에서처럼 함수 h(x)를 그냥 쓰면 간단하겠지만, h(x)는 비선형 함수이기 때문에 이를 사용하면 결과값이 더이상 Gaussian 분포를 따르지 않게 된다는 문제가 있다. 칼만 필터는 Gaussian 분포를 바탕으로 동작하기 때문이다. 기존의 행렬 H도 사용할 수 없고, 함수 h(x)도 사용할 수 없다면 어떡해야 하지?</p>

<p>비선형 함수인 h(x)와 가장 비슷한 분포를 가진 선형 함수를 행렬(Jacobian 행렬)을 찾아 기존의 행렬 H를 대체한다. h(x)의 Jacobian 행렬을 찾는 과정은 아마 미적분 공부를 해야 정확히 이해할 수 있을 것 같다.</p>

<p><img src="http://localhost:4000/images/ml/udacity/ekf-note2.png" alt="Note2" title="Jacobian" /></p>

<h2 id="종합">종합</h2>
<p><img src="http://localhost:4000/images/ml/udacity/kf-process.png" alt="KF Process" title="칼만필터 과정" /></p>

<p>칼만필터는 센서값을 가지고 물체의 다음 움직임을 예측하고, 예측값을 튜닝하는 과정을 반복하는 것으로 이루어져 있다. 자율주행차에서는 LADAR와 RIDAR 센서를 사용하여 주변 환경을 인식하는데, 특히 RIDAR 센서를 사용할 때는 센서값이 LADAR와 다른 형태이기 때문에 이를 변형하는 과정이 추가된다. Delta t는 이전 센서값과 현재 센서값 사이의 시간 차이를 나타내고, 두 종류의 센서값이 번갈아가면서 입력되기 때문에, 값을 다룰 때 어떤 센서의 값인지 구분하여야 한다.</p>

                </div>
                <div class="read-all">
                    <a  href="/2018/06/21/kalman-filter-2/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2018/06/20/kalman-filter-1/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (1)</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2018-06-20
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Udacity-SDCND" title="Category: Udacity-SDCND" rel="category">Udacity-SDCND</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a>&nbsp;
    
        <a href="/tag/#SelfDriving-Car" title="Tag: SelfDriving-Car" rel="tag">SelfDriving-Car</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    
<p>Udacity Self-Driving Car Nanodegree Term 2의 첫 과제는 칼만 필터를 구현하는 것이다.</p>

<p>칼만 필터는 자동차에 부착된 센서(LASER, RIDAR)를 통해 입력된 값을 통해서 차량 주변의 보행자, 자전거, 자동차 등의 물체를 인식하고 움직임을 예측하는 데 사용된다. 수업에서는 칼만 필터를 다루기 전에 Localization의 개념을 먼저 소개하는데 Localization은 다른 포스팅을 통해서 자세히 정리하도록 한다.</p>

<h2 id="칼만-필터란">칼만 필터란?</h2>

<p>현재까지 이해하기로는, (수업에서 다루는 물체 인식을 위한 용도) 칼만 필터는 업데이트된 센서값 + 현재까지 누적된 정보를 사용하여 주변 물체의 단위 시간 후의 위치를 예측한다.<br />
보행자를 추적한다고 예를 들면, 자동차의 입장에서 보행자가 현재 (x, y) 위치에 있다고 생각하는 것은 참값이 아니라, 사실 확률 분포로 인식하는 것이다 (주어진 정보로 미루어보아 현재로선 보행자가 저기 있을 확률이 가장 크다고 판단하는 것!). 또한, 센서값을 통해 물체의 위치가 연속적으로 주어지기 때문에 현재 위치와 직전 위치를 비교하면 물체의 이동 속도를 예측할 수 있게 된다.</p>

<p>칼만 필터는 연속적으로 주어지는 센서값을 가지고 물체의 위치와 속도를 예측하면서 동시에 예측에 쓰이는파라미터를 튜닝해가는 일련의 과정이라고 이해하고 있다.</p>

<p><img src="http://localhost:4000/images/ml/udacity/kf-process.png" alt="KF Process" title="칼만필터 과정" /></p>

<p>LIDAR와  RADAR 센서값을 받으면 먼저 현재까지의 정보를 바탕으로 물체의 위치(와 속도)를 예측하고, 이번에 받은 센서값을 활용해서 파라미터(행렬)을 업데이트하는 과정을 반복한다.</p>

<h2 id="lidar-센서">LIDAR 센서</h2>
<p>LIDAR 센서는 물체의 위치에 대한 값만 알아낸다 (속도에 대한 정보 없음).</p>

<h3 id="1d">1D</h3>

<p><img src="http://localhost:4000/images/ml/udacity/kf1-note1.png" alt="Note1" title="KF in 1D" /></p>

<p>Prediction 과정에서는 현재 우리가 가지고 있는 위치와 속도 정보만 가지고 t+1에서의 위치를 예측한다. Extended Kalman Filter에서는 물체의 이동 속도는 일정하다고 가정한다 (v’ = v).</p>

<p>Measurement Update 과정에서는 새롭게 얻은 센서값과 우리의 예측값을 비교하여 최종 예측값을 도출한다.</p>

<h3 id="2d">2D</h3>

<p>기본적인 골격은 1차원과 같지만, 2차원에서는 물체의 위치와 속도가 x축과 y축이 각각 있어야 하기 때문에 x 벡터의 모양이 바뀌었다. 이에 따라 행렬 F와 H, Q 값이 바뀐다.</p>

<p><img src="http://localhost:4000/images/ml/udacity/kf1-note2.png" alt="Note2" title="KF in 2D" /></p>

                </div>
                <div class="read-all">
                    <a  href="/2018/06/20/kalman-filter-1/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2017/12/17/linear-regression/">[Machine Learning] 선형회귀 (Linear Regression)</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2017-12-17
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Machine-Learning" title="Category: Machine-Learning" rel="category">Machine-Learning</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a>&nbsp;
    
        <a href="/tag/#Linear-Regression" title="Tag: Linear-Regression" rel="tag">Linear-Regression</a>&nbsp;
    
        <a href="/tag/#지도학습" title="Tag: 지도학습" rel="tag">지도학습</a>&nbsp;
    
        <a href="/tag/#Beginner" title="Tag: Beginner" rel="tag">Beginner</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<h2 id="선형회귀모델">선형회귀모델</h2>
<p>이번 포스트부터는 드디어 실제로 기계학습에서 사용되는 모델들과 적용 방법들을 다룰 것이다. 어느 입문서에서든 가장 먼저 설명하는 모델이 선형회귀모델인데, 여러 모델 중에서 가장 이해하기 쉽고, 간단한 모델이기 때문이다.</p>

<p>통계학개론을 배운 사람이라면 기본적인 회귀분석 모델에 대한 지식은 있을테지만, 간단히 설명하자면 종속변수 X와 독립변수 Y의 n차 관계식을 찾는 모델이라고 생각하면 된다. 함수식을 찾는다고 생각하면 될 것이다. 회귀분석 모델에서 가장 많이 언급되는 것이 바로 이번 포스트에서 설명할 선형회귀 모델인데, 이름에서도 나타나듯이 X와 Y의 관계를 선형으로 나타내는 모델을 의미한다. 선형이라는 것은 간단히 1차식으로 표현한다고 이해하면 된다.</p>

<p>아래와 같은 데이터가 있다고 가정해보자.<br />
<img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/linear_regression_sample.png" alt="선형회귀" /><br />
가로축 X와 세로축 Y가 정확히 어떻게 관계인지는 몰라도 X와 Y를 어느정도 직선으로 표현할 수 있다는 것은 눈치챌 수 있다. 선형회귀모델은 X와 Y의 관계를 가장 잘 나타내는 직선을 찾아내는 과정이다.</p>

<p><img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/1_supervised_linear_regression_definition.JPG" alt="선형회귀" /></p>

<p>선형회귀 모델은 크게 두가지로 나뉘는데, 설명 변수 X가 하나인 경우는 단순선형회귀, 여러 개인 경우는 다중선형회귀라고 한다. 선형회귀 모델은 X와 Y의 관계를 1차식으로 나타내는 것이기 때문에 두 경우 모두 간단히 아래와 같은 식으로 표현할 수 있다.</p>

<p>\({y=Wx+b}\)</p>

<p>다만, 단순선형회귀의 경우는 x 위치에 하나의 실수가 들어가고, 다중선형회귀는 여러 실수를 담은 벡터가 들어간다(자세한 내용은 마지막 챕터에서 다루는 것으로 한다). 식에서 W는 가중치(Weight)로 결과값 Y에 설명변수 X가 얼마나 영향을 주는지 나타낸다. b는 편향(또는 오차항)을 나타내는데, X만으로 설명할 수 없는 모든 오차값들을 표현한다.</p>

<p>기계학습을 통해서 우리는 X와 Y의 관계를 가장 잘 표현하는 관계식을 찾는다는 것은, 결국 가장 적절한 W와 b값을 찾는다는 것을 의미한다.</p>

<h2 id="단순선형회귀">단순선형회귀</h2>
<p><img src="http://localhost:4000/images/ml/ML_BASIC/Supervised_Learning/2_supervised_linear_regression_one_variable.JPG" alt="단순선형회귀" /></p>

<p>단순선형회귀는 결과값 Y에 영향을 미치는 변수가 하나라는 가정이다. 위에서 본 그래프와 같이 하나의 X와 대응되는 Y값이 주어질 때 둘의 관계를 찾는 것이다. 따라서 W와 b 값은 모두 하나의 실수로 구성된다. 학습의 결과는 \({y’=0.5x+3}\) 과 같이 최종 W와 b 값으로 대치된 하나의 식으로 나타날 것이다.</p>

<p>그렇다면 가장 적절한 W와 b 값은 어떤 과정을 찾아내는 것일까? 지난 포스트까지 설명했던 학습과정을 그대로 적용하면 된다.</p>
<ol>
  <li>모델(또는 가설)을 세워서 적용하고,</li>
  <li>세운 가설을 평가하고,</li>
  <li>평가를 바탕으로 가설을 업데이트한다.</li>
</ol>

<p>여기서 ‘모델’이라고 한 것은 특정한 W와 b값을 적용한 관계식인데, 위의 과정을 우리가 알고 있는 과정에 대입하면 아래와 같다.</p>
<ol>
  <li>\({y’=0.5x+3}\)라는 모델을 가지고 예측값 y’를 계산한다.</li>
  <li>MSE를 사용하여 실제값 y와 예측값 y’의 오차를 계산한다.</li>
  <li>오차에 따라 경사하강법으로 W와 b 값을 업데이트한다.</li>
</ol>

<p>실제 데이터에 적용해보자. 먼저 예제에 사용할 (x, y) 데이터쌍 200개를 생성한다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="k">def</span> <span class="nf">create_dataset</span><span class="p">()</span> <span class="p">:</span>
    <span class="n">data_size</span> <span class="o">=</span> <span class="mi">200</span>
    <span class="n">dataset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data_size</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="mf">0.1</span> <span class="o">+</span> <span class="mf">0.3</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.03</span><span class="p">)</span>
        <span class="n">dataset</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>

    <span class="n">x_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
    <span class="n">y_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
</code></pre></div></div>

<p>첫번째 Iteration을 위해 W와 b의 초기값을 설정한다. 보통 W값은 랜덤으로, b값은 0으로 시작한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">model</span><span class="p">[</span><span class="s">'W'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
<span class="n">model</span><span class="p">[</span><span class="s">'b'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>

<span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="c"># 일반 파이썬 리스트에서 numpy array로 변환</span>
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>
</code></pre></div></div>

<p>위에서 설명한 세가지 과정을 코드로 표현해보자.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 1. 현재의 모델로 예측값 y'를 계산</span>
<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">x_data</span>
    <span class="k">return</span> <span class="n">x_data</span> <span class="o">*</span> <span class="n">model</span><span class="p">[</span><span class="s">'W'</span><span class="p">]</span> <span class="o">+</span> <span class="n">model</span><span class="p">[</span><span class="s">'b'</span><span class="p">]</span>


<span class="c"># 2. 오차 계산 (MSE)</span>
<span class="k">def</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"MSE model : "</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">global</span> <span class="n">x_data</span>
    <span class="k">global</span> <span class="n">y_data</span>
    <span class="n">y_predict</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>  <span class="c"># 현재의 가설을 바탕으로 x 데이터에 대한 예측값 y를 리턴하는 함수</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c"># 훈련 데이터의 개수</span>
    <span class="n">mse</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">m</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">y_predict</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"loss : "</span><span class="p">,</span> <span class="n">mse</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mse</span>


<span class="c"># 편미분 계산</span>
<span class="k">def</span> <span class="nf">derivative</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="p">:</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">temp</span> <span class="o">=</span> <span class="n">model</span>
        <span class="n">temp</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span>
        <span class="n">plus</span> <span class="o">=</span> <span class="n">function</span><span class="p">(</span><span class="n">temp</span><span class="p">)</span>
        
        <span class="c"># 원래는 (+h ~ -h) 한 값의 기울기를 구하는 게 더 정확하다</span>
        <span class="n">grads</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">plus</span> <span class="o">-</span> <span class="n">function</span><span class="p">(</span><span class="n">model</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">h</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">grads</span>


<span class="c"># 3. 경사하강법으로 변수 업데이트</span>
<span class="k">def</span> <span class="nf">gradient_descent_with_derivative</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">model</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">derivative</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
    
    <span class="c"># 편미분 구한 값을 learning rate만큼 반영하여 업데이트</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span>
        <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">-=</span> <span class="p">(</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">grads</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
    

<span class="c"># 실제로 테스트해보자</span>
<span class="c"># 100번을 실험하면서 W와 b 값이 어떻게 변화하는지 살펴본다</span>
<span class="n">iteration</span> <span class="o">=</span> <span class="mi">100</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
    <span class="n">gradient_descent_with_derivative</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"model : "</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre></div></div>

<p>실험을 하면서 주의깊게 봐야하는 값은 사실 Loss이다. 학습의 목표가 Loss 값을 최소화하는 것임을 기억하면, Iteration이 계속되면서 Loss 값이 점점 커지는 상황이 발생했을 때, learning rate을 조절해서 Loss가 발산하지 않도록 수정해야 한다. Learning Rate은 W와 b 값을 업데이트 할 때 한번에 움직이는 보폭을 얼마나 크게 할 것인지 결정하는 변수이다. Loss 값이 발산한다는 것은 한번에 너무 많이 움직인다는 것을 의미하기 때문에 이럴 때는 Learning Rate을 더 작게 해서 보폭을 작게 만들어야 한다.</p>

<h2 id="tensorflow-이용해서-구현하기">Tensorflow 이용해서 구현하기</h2>
<p>사실 파이썬만으로도 기계학습 알고리즘을 구현할 수는 있지만 위에서 보듯이 코드가 복잡해지고 작성자가 신경써야할 부분도 많아진다. 그래서 보통 기계학습 알고리즘을 적용할 때 본인이 직접 모든 코드를 구현하기 보다 미리 만들어져 있는 소스를 활용하는데 가장 많이 사용되는 것이 구글에서 제공하는 Tensorflow이다. Tensorflow를 활용하면 Gradient Descent나 Loss 계산 이런 것들을 미리 만들어져있는 함수에 맡기고 우리는 틀만 짜주면 된다.</p>

<p>Tensorflow를 활용하면 위의 복잡한 코드가 아래처럼 간단해진다. 물론 그 전에 Tensorflow 패키지를 모두 설치해야 한다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span>

<span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span> <span class="o">=</span> <span class="n">create_dataset</span><span class="p">()</span>
<span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> 
<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">y_data</span><span class="p">)</span>

<span class="c"># Tensorflow를 사용할 때는 학습을 진행하기 전에</span>
<span class="c"># 먼저 어떠한 방식으로 학습시킬지 변수들을 먼저 설정해주어야 한다.</span>
<span class="c"># 설정해야 하는 변수에는 관계식 W와 b, Loss 함수, 최적화 방식 등이 있다.</span>

<span class="c"># tf.Variable() 함수는 학습시켜야 하는 변수를 만들어 준다.</span>
<span class="c"># 여기서 W와 b는 모두 실수 하나로 구성된다.</span>
<span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_uniform</span><span class="p">([</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">]))</span>

<span class="c"># x와 y의 관계식을 설정한다. </span>
<span class="n">y</span> <span class="o">=</span> <span class="n">W</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">b</span>
<span class="c"># loss는 실제값 y_data와 예측값 y의 MSE를 구하는 방식으로 설정</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_data</span><span class="p">))</span>

<span class="c"># 최적화는 우리가 배운 Gradient Descent 방식을 사용한다.</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">GradientDescentOptimizer</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span>

<span class="c"># 학습은 loss로 설정한 MSE를 minimize(최소화) 하는 방식으로 사용한다.</span>
<span class="n">train</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span> 

<span class="c"># 여기까지는 학습 변수 설정이고</span>
<span class="c"># 실제 학습은 Session 안에서 이루어진다. </span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span> <span class="p">:</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">())</span> <span class="c"># 변수 W, b 초기화</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iteration</span><span class="p">):</span>
        <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">),</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

<span class="c"># 그래프 출력</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">,</span> <span class="s">'ro'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">W</span><span class="p">)</span> <span class="o">*</span> <span class="n">x_data</span> <span class="o">+</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>Loss 함수나 최적화 함수를 직접 작성할 때보다 코드가 훨씬 간결해졌다. Tensorflow를 활용하면 우리는 학습이 진행되면서 나오는 결과 분석에만 신경쓰면 되고, 나머지는 Tensorflow에 맡겨두면 된다. 앞으로 예제 코드는 Tensorflow를 사용하는 버전으로 작성하도록 하고, 우리는 원리를 이해하는 데 집중하도록 하자.</p>

                </div>
                <div class="read-all">
                    <a  href="/2017/12/17/linear-regression/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
              <li>
                <h2>
                  <a class="post-link" href="/2017/12/09/gradient-descent/">[Machine Learning] 학습 프로세스 (3단계. 모델업데이트)</a>
                </h2>
                <div class="label">
                    <div class="label-card">
                        <i class="fa fa-calendar"></i>2017-12-09
                    </div>
                    <div class="label-card">
                        
                    </div>
                    <div class="label-card">
                        
                    </div>

                    <div class="label-card">
                    


<!-- <span class="point">•</span> -->
<span class="categories">
  <i class="fa fa-th-list"></i>
  
    
        <a href="/category/#Machine-Learning" title="Category: Machine-Learning" rel="category">Machine-Learning</a>
    
  

  <!-- <span class="point">•</span> -->
</span>


                    </div>

                    <div class="label-card">
                    
<!-- <span class="point">•</span> -->
<span class="pageTag">
  <i class="fa fa-tags"></i>
  
    
        <a href="/tag/#Machine-Learning" title="Tag: Machine-Learning" rel="tag">Machine-Learning</a>&nbsp;
    
        <a href="/tag/#Beginner" title="Tag: Beginner" rel="tag">Beginner</a>
    
  

</span>

                    </div>
                </div>
                <div class="excerpt">
                    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

<p>이번 포스트에서는 학습 프로세스의 마지막 단계인 3단계, 모델 업데이트 방법을 소개하고자 한다. 모델 업데이트는 학습 결과와 실제 정답을 비교하여 모델을 평가한 다음, 그에 맞는 피드백을 제공하여 실제 정답에 근접한 모델을 찾아가기 위해 필요한 과정이다.</p>

<p><img src="http://localhost:4000/images/ml/ML_BASIC/ML_Basic_Concept/7-1_ML_Basic_Gradient_Descent_1.jpg" alt="Model Update" /></p>

<p>모델은 간단히 말해 변수들 간의 관계식이다. 중학교 수학에서 배웠던 방정식은 \(y=Wx+b\) 이라는 관계식이 정해져 있고, 관계식에 따라 y에 상응하는 x값을 찾는 것이었다. 기계학습은 반대로 (x, y)의 데이터가 주어졌을 때 이 둘의 관계를 가장 잘 설명하는 W와 b 값을 귀납적인 방법으로 찾아간다. 지난 포스트에서 다뤘던 손실함수를 사용해서 손실함수의 값을 최소화하는 방향으로 가중치를 바꿔가면 정답에 근접한 관계식을 찾을 수 있다.</p>

<p>다시 중학교 수학으로 돌아가보자. 어떤 함수의 최소값/최대값은 그래프의 기울기가 0인 지점이다. 그렇다면 손실함수 그래프에서도 기울기가 0인 지점을 계산하면 쉽게 정답을 찾을 수 있지 않을까? 변수가 한 두개 정도인 간단한 모델이라면 단순 계산으로 최소값을 찾을 수 있겠지만, 그렇다면 기계학습을 공부하는 의미가 없을 것이다. 기계학습을 사용해서 찾고자 하는 모델은 보통 변수가 굉장히 많고, 변수 간의 관계가 복잡하기 때문에 계산으로 한번에 최소값을 찾는 것이 거의 불가능하다.</p>

<p>손실함수 그래프 전체적인 모양은 계산할 수 없다고 해도 현재 위치에서의 <strong>순간기울기(Gradient)</strong>는 미분으로 알 수 있기 때문에 그 위치에서 <strong>조금씩 아래로 내려가다(Descent)</strong>보면 기울기가 0인 지점이 나오지 않을까 하는 것이 이번 포스트에서 설명할 <strong>경사하강법(Gradient Descent)</strong>의 기본 아이디어이다.</p>

<h2 id="경사하강법">경사하강법</h2>
<h3 id="변수가-하나인-경우">변수가 하나인 경우</h3>

<p>변수가 하나인 가장 단순한 모델을 통해 경사하강법을 이해해보자.</p>

<p><img src="http://localhost:4000/images/ml/ML_BASIC/ML_Basic_Concept/7-2_ML_Basic_Gradient_Descent_2.jpg" alt="Gradient Descent with One Variable" /></p>

<p>앞서 설명했듯이 경사하강법은 매 업데이트마다 순간기울기의 일정 비율만큼 움직인다. 이것을 식으로 나타내면 아래와 같다.<br />
\(\large {x=x-\gamma \ast \frac { dJ }{ dx } }\)</p>

<p>현재 위치의 순간기울기는 손실함수 J에 대해 x의 미분으로 구할 수 있고, 기존의 변수 x에 순간기울기의 일정비율(learning rate) 만큼을 빼주면 다음 학습에 사용할 x값이 업데이트 된다. 이 식이 유효한 이유는 무엇인지는 그래프를 보면 쉽게 이해할 수 있다.</p>

<blockquote>
  <p>눈을 가린 상태에서 산을 내려간다고 상상해보자. 나는 현재 나의 위치에 대한 정보만 있을 뿐, 산이 전체적으로 알 수 없다. 그렇다고 산을 내려갈 수 없는 것은 아니다. 현재 나의 위치에서 발의 감각으로 오르막인지, 내리막인지 알 수 있기 때문에 내리막길의 방향으로 한발짝씩 움직이면 산을 내려갈 수 있다.</p>
</blockquote>

<p>경사하강법도 마찬가지이다. 우리가 찾아가야 하는 지향점은 손실함수 J의 값이 최소인 즉, 기울기가 0인 지점이다. 하지만 그래프 전체의 모양은 알 수 없기 때문에 그래프 상 현재 위치에서 내리막이 어딘지를 찾고 내리막 방향으로 조금씩 움직여 보는 것이다. 그래프에서 오른쪽과 같이 순간기울기가 양수인 경우라면 뒤로 가야 내리막이기 때문에 기존 변수 x 값에 기울기만큼 빼주면 골짜기에 가까워지고 반대로 순간기울기가 음수인 경우라면 앞으로 가야 내리막이기 때문에 변수 x에 기울기만큼 더해주면(음수만큼 빼주면) 골짜기에 가까워진다.</p>

<h3 id="learning-rate-r">Learning Rate, r</h3>

<p>식에서 나오는 \(\gamma\)는 learning rate라고 하는 값인데, 한발짝을 기울기에 비례해서 얼마나 크게 내딛을지 결정하는 값이다. 대담한 사람이라면 내리막 방향으로 크게 한발짝 내딛을 것이고, 신중한 사람이라면 종종걸음으로 내려갈 것이다. learning rate은 최소값을 찾아가는 효율과도 관련이 있는데, 종종걸음으로 내려가는 것이 훨씬 더 정확하게 골짜기를 찾아갈 수는 있지만 걸음수와 시간은 많이 들 것이고, 큰 걸음으로 내려간다면 시간은 훨씬 덜 들 수 있지만, 골짜기에 가까이 가서는 계속 반대쪽 등성이로 발을 내딛어 골짜기 자체에는 다다르지 못하는 경우(수렴하지 못하고 발산하는 경우)가 발생할 수 있다. 따라서 적당한 Learning Rate을 결정하는 것도 기계학습에서 중요한 이슈이다(대부분의 예제에서는 0.1을 사용한다).</p>

<h3 id="변수가-여러-개인-경우">변수가 여러 개인 경우</h3>

<p><img src="http://localhost:4000/images/ml/ML_BASIC/ML_Basic_Concept/7-3_ML_Basic_Gradient_Descent_3.jpg" alt="Gradient Descent with One Variable" /></p>

<p>변수가 여러 개인 경우의 경사하강법도 원리는 동일하다. 다만 매 업데이트마다 각 변수들의 값을 모두 수정해주면 된다.  그래프 상에서 보듯이 변수가 여러 개인 경우 손실함수의 그래프는 2차원 이상으로 나타나고, 그마저도 3차원 이상인 경우에는 그래프로 표현할 수 없다. 연역적인 방법으로 최소값을 찾을 수 없기 때문에 경사하강법이 절실하다.</p>

<p>변수가 여러 개인 경우는 변수 하나인 경우에 소개했던 식을 각 변수에 적용하면 된다.</p>

<p>변수 업데이트 과정을 파이썬 코드로 나타내면 다음과 같다.</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">"""
function : 미분을 구할 함수
x : 편미분 기준 변수

x의 위치에서 순간기울기를 구하는 함수
함수에 따라서 편미분 식이 달라지기 때문에 General하게 사용하기 위해 
x를 기준으로 작은 값 h만큼 위아래로 움직였을 때의 기울기를 계산한다.
"""</span>
<span class="k">def</span> <span class="nf">derivative</span><span class="p">(</span><span class="n">function</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">h</span> <span class="o">=</span> <span class="mf">1e-4</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="n">h</span><span class="p">)</span> <span class="o">-</span> <span class="n">function</span><span class="p">(</span><span class="n">x</span><span class="o">-</span><span class="n">h</span><span class="p">))</span> <span class="o">/</span> <span class="mi">2</span><span class="o">*</span><span class="n">h</span>

<span class="s">"""
model : 모델에서 사용하는 변수 값 리스트
loss_function : 손실함수

model 변수에는 모델에서 사용하는 변수의 값들이 들어있고, 본 함수에서는 그 값들을 돌아가면서 업데이트하여 리턴한다.
업데이트하는 방식은 위에서 설명하였듯이 기존의 값에서 순간기울기 만큼을 빼는 방식을 사용한다.
learning_rate은 default 0.1로 적용하였다.
"""</span>
<span class="k">def</span> <span class="nf">gradient_descent_with_derivative</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss_function</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span> <span class="p">:</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span> <span class="p">:</span>
        <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">]</span> <span class="o">-=</span> <span class="n">derivative</span><span class="p">(</span><span class="n">loss_function</span><span class="p">,</span> <span class="n">model</span><span class="p">[</span><span class="n">param</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div></div>

                </div>
                <div class="read-all">
                    <a  href="/2017/12/09/gradient-descent/"><i class="fa fa-newspaper-o"></i>Read All</a>
                </div>
                <hr>
              </li>
            
        </ul>



        <!-- Pagination links -->
        <div class="pagination">
          
            <a href="/index.html" class="previous"><i class="fa fa-angle-double-left"></i></a>
            <a href="/" class="previous"><i class="fa fa-angle-left"></i></a>
          
          <span class="page_number ">2/4</span>
          
            <a href="/page3" class="next"><i class="fa fa-angle-right"></i></a>
            <a href="/page4" class="next"><i class="fa fa-angle-double-right"></i></a>
          
        </div>
    </div>
    <!-- <button class="anchor"><i class="fa fa-anchor"></i></button> -->
    <div class="right">
        <div class="wrap">
            <div class="side">
                <div>
                    <i class="fa fa-pencil-square-o" aria-hidden="true"></i>
                    Recent Posts
                </div>
                <ul class="content-ul" recent>
                    
                        <li><a href="/2018/07/30/8_4_fundamental_subspaces/">[선형대수] 8강 : 4가지 부 벡터 공간</a></li>
                    
                        <li><a href="/2018/07/26/7_linear_independent/">[선형대수] 7강 : 선형독립 및 기저벡터</a></li>
                    
                        <li><a href="/2018/07/25/6_null_space/">[선형대수] 6강 : 영벡터공간과 해집합</a></li>
                    
                        <li><a href="/2018/07/25/5_vector_space/">[선형대수] 5강 : 벡터 공간과 열벡터</a></li>
                    
                        <li><a href="/2018/06/29/4_inverse_transpose/">[선형대수] 4강 : 역행렬과 전치행렬</a></li>
                    
                        <li><a href="/2018/06/26/3_elementary-matrix/">[선형대수] 3강 : LU Decomposition</a></li>
                    
                        <li><a href="/2018/06/26/2_gaussian-elimination/">[선형대수] 2강 : 1차 연립방정식과 가우스소거법</a></li>
                    
                        <li><a href="/2018/06/22/1_linearity/">[선형대수] 1강 : 선형성의 정의 및 1차 연립방정식의 의미</a></li>
                    
                        <li><a href="/2018/06/21/kalman-filter-2/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (2)</a></li>
                    
                        <li><a href="/2018/06/20/kalman-filter-1/">[Udacity SDCND] 칼만필터 Kalman Filter 이해하기 (1)</a></li>
                    
                </ul>
            </div>

            <!-- Content -->
            <div class="side ">
                <div>
                    <i class="fa fa-th-list"></i>
                    Categories
                </div>
                <ul class="content-ul" cate>
                    
                    <li>
                        <a href="/category/#Python" class="categories-list-item" cate="Python">
                            <span class="name">
                                Python
                            </span>
                            <span class="badge">4</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#강화학습" class="categories-list-item" cate="강화학습">
                            <span class="name">
                                강화학습
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#Coursera" class="categories-list-item" cate="Coursera">
                            <span class="name">
                                Coursera
                            </span>
                            <span class="badge">1</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#Machine-Learning" class="categories-list-item" cate="Machine-Learning">
                            <span class="name">
                                Machine-Learning
                            </span>
                            <span class="badge">4</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#Udacity-SDCND" class="categories-list-item" cate="Udacity-SDCND">
                            <span class="name">
                                Udacity-SDCND
                            </span>
                            <span class="badge">2</span>
                        </a>
                    </li>
                    
                    <li>
                        <a href="/category/#Linear-Algebra" class="categories-list-item" cate="Linear-Algebra">
                            <span class="name">
                                Linear-Algebra
                            </span>
                            <span class="badge">8</span>
                        </a>
                    </li>
                    
                </ul>
            </div>
            <!-- 其他div框放到这里 -->
            <div class="side">
                <div>
                    <i class="fa fa-tags"></i>
                    Tags
                </div>
                <div class="tags-cloud">
                    
                    
                    
                    

                    

                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Python" style="font-size: 13pt; color: #555;">Python</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#강화학습" style="font-size: 9pt; color: #999;">강화학습</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#OpenAI-Gym" style="font-size: 9pt; color: #999;">OpenAI-Gym</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Frozen-Lake" style="font-size: 9pt; color: #999;">Frozen-Lake</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Deep-Learning" style="font-size: 10.5pt; color: #888;">Deep-Learning</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Coursera" style="font-size: 10.5pt; color: #888;">Coursera</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Machine-Learning" style="font-size: 15.5pt; color: #333;">Machine-Learning</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Beginner" style="font-size: 13pt; color: #555;">Beginner</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Linear-Regression" style="font-size: 9pt; color: #999;">Linear-Regression</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#지도학습" style="font-size: 9pt; color: #999;">지도학습</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#SelfDriving-Car" style="font-size: 10.5pt; color: #888;">SelfDriving-Car</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Math" style="font-size: 18pt; color: #000;">Math</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#Linear-Algebra" style="font-size: 18pt; color: #000;">Linear-Algebra</a>
                    
                      
                      
                      
                      
                      
                      <a href="/tag/#KMOOC" style="font-size: 18pt; color: #000;">KMOOC</a>
                    
                </div>
            </div>

            <!-- <div class="side">
                <div>
                    <i class="fa fa-external-link"></i>
                    Links
                </div>
                <ul  class="content-ul">

                </ul>
            </div> -->
        </div>
    </div>
</div>
<!-- <script src="/js/scroll.min.js " charset="utf-8"></script> -->
<!-- <script src="/js/pageContent.js " charset="utf-8"></script> -->


    <footer class="site-footer">


    <div class="wrapper">

        <p class="description">
            
        </p>
        <p class="contact">
            Contact me at: 
            <a href="https://github.com/ahracho" title="GitHub"><i class="fa fa-github" aria-hidden="true"></i></a>  
            <a href="mailto:ahracho89@gmail.com" title="email"><i class="fa fa-envelope-o" aria-hidden="true"></i></a>     
            <a href="https://www.facebook.com/ahra.cho3" title="Facebook"><i class="fa fa-facebook-official" aria-hidden="true"></i></a>    
        </p>
        <p class="power">
            <span>
                Site powered by <a href="https://jekyllrb.com/">Jekyll</a> & <a href="https://pages.github.com/">Github Pages</a>.
            </span>
            <span>
                Theme designed by <a href="https://github.com/Gaohaoyang">HyG</a>.
            </span>
        </p>
    </div>
</footer>
<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <div class="back-to-top">
    <a href="#top" data-scroll>
        <i class="fa fa-arrow-up" aria-hidden="true"></i>
    </a>
</div>

    <script src=" /js/main.js " charset="utf-8"></script>
    <script src=" /js/smooth-scroll.min.js " charset="utf-8"></script>
    <script type="text/javascript">
      smoothScroll.init({
        speed: 500, // Integer. How fast to complete the scroll in milliseconds
        easing: 'easeInOutCubic', // Easing pattern to use
        offset: 20, // Integer. How far to offset the scrolling anchor location in pixels
      });
    </script>
    <!-- <script src=" /js/scroll.min.js " charset="utf-8"></script> -->
  </body>

</html>
